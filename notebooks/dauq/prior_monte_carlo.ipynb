{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and process the prior monte carlo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.rcParams['font.size']=12\n",
    "import flopy\n",
    "import pyemu\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUPER IMPORTANT: SET HOW MANY PARALLEL WORKERS TO USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the `t_d` or \"template directory\" variable to point at the template folder and read in the PEST control file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_d = \"template\"\n",
    "pst = pyemu.Pst(os.path.join(t_d,\"freyberg.pst\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just a reminder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_d = os.path.join(\"..\",\"..\",\"data\",\"freyberg_nwt\")\n",
    "nam_file = \"freyberg.nam\"\n",
    "m = flopy.modflow.Modflow.load(nam_file,model_ws=b_d,check=False,forgive=False)\n",
    "# plot some model attributes\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "ax = plt.subplot(111,aspect=\"equal\")\n",
    "mm = flopy.plot.ModelMap(model=m)\n",
    "mm.plot_grid()\n",
    "mm.plot_ibound()\n",
    "mm.plot_bc('SFR')\n",
    "ax = mm.ax\n",
    "#m.wel.stress_period_data.plot(ax=ax,mflay=2)\n",
    "\n",
    "# plot obs locations\n",
    "obs = pd.read_csv(os.path.join(b_d,\"obs_loc.csv\"))\n",
    "                  \n",
    "obs_x = [m.sr.xcentergrid[r-1,c-1] for r,c in obs.loc[:,[\"row\",\"col\"]].values]\n",
    "obs_y = [m.sr.ycentergrid[r-1,c-1] for r,c in obs.loc[:,[\"row\",\"col\"]].values]\n",
    "ax.scatter(obs_x,obs_y,marker='.',label=\"water-level obs\",s=80)\n",
    "\n",
    "#plot names on the pumping well locations\n",
    "wel_data = m.wel.stress_period_data[0]\n",
    "wel_x = m.sr.xcentergrid[wel_data[\"i\"],wel_data[\"j\"]]\n",
    "wel_y = m.sr.ycentergrid[wel_data[\"i\"],wel_data[\"j\"]]\n",
    "for i,(x,y) in enumerate(zip(wel_x,wel_y)):\n",
    "    ax.scatter([x],[y],color=\"red\",marker=\"s\",s=50)\n",
    "    #ax.text(x,y,\"{0}\".format(i+1),ha=\"center\",va=\"center\")\n",
    "\n",
    "ax.set_ylabel(\"y(m)\")\n",
    "ax.set_xlabel(\"x(m)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the previously generated parameter ensemble and inspect (again!)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pyemu.ParameterEnsemble.from_binary(pst=pst,filename=os.path.join(t_d,\"prior.jcb\"))\n",
    "#pe.loc[:,should_fix] = 1.0\n",
    "pe.to_csv(os.path.join(t_d,\"sweep_in.csv\"))\n",
    "pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe.loc[:,\"hk031\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe.loc[:,\"hk031\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look! hk is log-normal-ish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run the first realization through the pest interface for a test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the par vals with the first row in the par ensemble\n",
    "pst.parameter_data.loc[pe.columns,\"parval1\"] = pe.iloc[0,:]\n",
    "pst.control_data.noptmax = 0\n",
    "pst.write(os.path.join(t_d,\"test.pst\"))\n",
    "pyemu.os_utils.run(\"pestpp-ies test.pst\",cwd=t_d)\n",
    "res = pyemu.pst_utils.read_resfile(os.path.join(t_d,\"test.base.rei\"))\n",
    "res.loc[pst.nnz_obs_names,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run the prior ensemble in parallel locally\n",
    "This takes advantage of the program `pestpp-swp` which runs a parameter sweep through a set of parameters. By default, `pestpp-swp` reads in the ensemble from a file called `sweep_in.csv` which in this case we made just above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d = \"master_prior_sweep\"\n",
    "pyemu.os_utils.start_workers(t_d,\"pestpp-swp\",\"freyberg.pst\",num_workers=num_workers,worker_root=\".\",master_dir=m_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the output ensemble and plot a few things\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df = pd.read_csv(os.path.join(m_d,\"sweep_out.csv\"),index_col=0)\n",
    "print('number of realization in the ensemble before dropping: ' + str(obs_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop any failed runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df = obs_df.loc[obs_df.failed_flag==0,:]\n",
    "print('number of realization in the ensemble **after** dropping: ' + str(obs_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df.iloc[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confirm which quantities were identified as forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = pst.pestpp_options[\"forecasts\"].split(',')\n",
    "fnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that the most extreme scenario yields a large decrease in flow from the aquifer to the headwaters (the most negative value).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "plt.figure()\n",
    "for forecast in fnames:\n",
    "    ax = plt.subplot(111)\n",
    "    obs_df.loc[:,forecast].hist(ax=ax,color=\"0.5\",alpha=0.5)\n",
    "    ax.plot([obs.loc[forecast,\"obsval\"],obs.loc[forecast,\"obsval\"]],ax.get_ylim(),\"r\")\n",
    "    ax.set_title(forecast)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many modeling analyses could stop right here to avoid the ill-effects of history matching...we have covered the \"truth\" for all forecasts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior-data conflict detection:\n",
    "\n",
    "Lets' see how the observation values stack up against the prior Monte Carlo results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for oname in pst.nnz_obs_names:\n",
    "    ax = plt.subplot(111)\n",
    "    obs_df.loc[:,oname].hist(ax=ax,color=\"0.5\",alpha=0.5)\n",
    "    ax.plot([obs.loc[oname,\"obsval\"],obs.loc[oname,\"obsval\"]],ax.get_ylim(),\"r\")\n",
    "    ax.set_title(oname)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see now that for two of the observations, the prior model output ensembles do not \"cover\" or \"bracket\" the corresponding observed values.  This means that extreme parameter values and and/or extreme parameter combinations will be need to force the model to fit these observations.  This is a clear source of bias!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
